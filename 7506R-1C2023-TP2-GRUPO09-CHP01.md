---
jupyter:
  jupytext:
    cell_metadata_filter: -all
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```python
try:
  import google.colab
  IN_COLAB = True
except:
  IN_COLAB = False
import pandas as pd 
import numpy as np

#modelos y metricas
import seaborn as sns
from matplotlib import pyplot as plt
from joblib import dump, load
from os.path import exists
from sklearn.model_selection import StratifiedKFold, KFold,RandomizedSearchCV, train_test_split, cross_validate
from sklearn.metrics import confusion_matrix, classification_report , f1_score, make_scorer, precision_score, recall_score, accuracy_score,f1_score

#Xval
from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score

#vectorizacion
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.pipeline import Pipeline

import sklearn ### ESTA NO SE BORRA ???? #TODO
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

from os.path import exists

import nltk



#Random forest
from sklearn.ensemble import RandomForestClassifier 

```

Constantes

```python
# Constantes
JOBS=-2
SEED=9
```

```python
reviewDfOriginal = pd.read_csv("./review_train.csv")
reviewDf = reviewDfOriginal.copy()
```

```python
review_pruebasOriginal = pd.read_csv("./review_test.csv")
review_pruebas = review_pruebasOriginal.copy()
```

```python
reviewDf = reviewDf.drop(["ID"],  axis='columns', inplace=False)
reviewDf
```

```python
reviewDf_x = reviewDf.drop(["sentimiento"],  axis='columns', inplace=False)

reviewDf_y = reviewDf['sentimiento'].copy()

x_train, x_test, y_train, y_test = train_test_split(reviewDf_x,
                                                    reviewDf_y,
                                                    test_size=0.30,
                                                    random_state=SEED,
                                                    shuffle=True
                                                    )
```

# Bayes Naive


Creamos el modelo


#TODO FALTA DUMPAEARKO Y OPTIMIZARLO

```python
modeloBayesNaive = make_pipeline(TfidfVectorizer(), MultinomialNB())

modeloBayesNaive.fit(x_train.review_es, y_train)

prediccion = modeloBayesNaive.predict(x_test.review_es)
```

Miramnos como fue en test

```python
#performance
print(classification_report(y_test,prediccion))


#Creamos la matriz de confusión
tabla=confusion_matrix(y_test, prediccion)

#Grafico la matriz de confusión
sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')
plt.xlabel('Predicho')
plt.ylabel('Verdadero')
```

Hacemos la submission

```python
if not exists('submissions/TP2/naiveBayes-0.csv'):
    prediccionTesteo = modeloBayesNaive.predict(review_pruebas.review_es)
    df_submission = pd.DataFrame({'id': review_pruebasOriginal['ID'], 'sentimiento': prediccionTesteo})
    df_submission.to_csv('submissions/TP2/naiveBayes-0.csv', index=False)
```

### Otimizacion Bayes Naive

```python
###### FALTA
```

# Random Forest


Creamnos el modelo con parametros arbitrarios parta obtener una prediccion inicial

```python
if exists('modelos/TP2/modeloRandomForest-0.joblib') == False:
    #Creamos un clasificador con hiperparámetros arbitrarios
    rfc = RandomForestClassifier(n_jobs=JOBS,
                                 criterion="entropy", 
                                 random_state=SEED, 
                                 min_samples_leaf=15,
                                 min_samples_split=40,
                                 n_estimators=40 )
    
    modeloRandomForest = make_pipeline(TfidfVectorizer(), rfc)

    modeloRandomForest.fit(x_train.review_es, y_train)

else:
    modeloRandomForest = load('modelos/TP2/modeloRandomForest-0.joblib')
```

Miramos como fue en test

```python
prediccion_rf = modeloRandomForest.predict(x_test.review_es)

#performance
print(classification_report(y_test,prediccion_rf))


#Creamos la matriz de confusión
tabla=confusion_matrix(y_test, prediccion)

#Grafico la matriz de confusión
sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')
plt.xlabel('Predicho')
plt.ylabel('Verdadero')  
```

Guardamos el modelo

```python
if exists('modelos/TP2/modeloRandomForest-0.joblib') == False:
    #Nos guardamos este modelo para poder cargarlo en todas las corridas posteriores
    dump(modeloRandomForest, 'modelos/TP2/modeloRandomForest-0.joblib')
else:
    modeloRandomForest = load('modelos/TP2/modeloRandomForest-0.joblib')
```

Hacemos la submission

```python
if not exists('submissions/TP2/randomForest-0.csv'):
    prediccionTesteo = modeloRandomForest.predict(review_pruebas.review_es)
    df_submission = pd.DataFrame({'id': review_pruebasOriginal['ID'], 'sentimiento': prediccionTesteo})
    df_submission.to_csv('submissions/TP2/randomForest-0.csv', index=False)
else:
    df_submission = load('submissions/TP2/randomForest-0.csv')

print(df_submission.head())
```

#### Optimizacion de hiperparametros con Cros Validation

```python
if exists('modelos/TP2/modeloRandomForestCv.joblib') == False:

    rfcv = RandomForestClassifier()


    modeloRandomForest_cv = Pipeline(steps= [ ('tfidfVectorizer', TfidfVectorizer() ), ('rfcv', rfcv) ] )

    param_grid = { "rfcv__criterion" : ["gini", "entropy"], 
   #                "rf_cv__min_samples_leaf" : [1,15, 20], #Vamos a hacer muchas combinaciones ya que solo vamos
  #                 "rf_cv__min_samples_split" : [2, 32, 64],#a correr este modelo 1 sola vez; ya que lo vamos a 
 #                  "rf_cv__n_estimators": [10, 60, 70] } #guardar   
}
    #Probamos entrenando sólo con 1 métrica: f1_scoree

    rf_gs = GridSearchCV(estimator=modeloRandomForest_cv, param_grid=param_grid, scoring="f1", cv=5, n_jobs=JOBS) #Optimizamos f1_score
    gs_fit = rf_gs.fit(x_train.review_es, y_train)
    
    #guardamos el grid search
    dump(gs_fit, 'modelos/randomForestCV.joblib')

else:
    gs_fit = load('modelos/randomForestCV.joblib')

gs_fit.best_params_
```

```python
# param_grid = { "criterion" : ["gini", "entropy"], 
#                    "min_samples_leaf" : [1, 5, 10, 15, 20], #Vamos a hacer muchas combinaciones ya que solo vamos
#                    "min_samples_split" : [2, 8, 16, 32, 64],#a correr este modelo 1 sola vez; ya que lo vamos a 
#                    "n_estimators": [10, 20, 30, 40, 50, 60, 70] } #guardar   

```

```python
#Obtenemos el mejor modelo
mejor_modelo_rf = gs_fit.best_estimator_

#Predicción
prediccion_mejor_modelo_rf = mejor_modelo_rf.predict(x_test)
prediccion_mejor_modelo_rf
```

<!-- #region -->
#performance
print(classification_report(y_test,prediccion_rf))


#Creamos la matriz de confusión
tabla=confusion_matrix(y_test, prediccion)

#Grafico la matriz de confusión
sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')
plt.xlabel('Predicho')
plt.ylabel('Verdadero')  
<!-- #endregion -->

# XGBoost



# Red Neuronal


# Ensamble de 3 modelos
