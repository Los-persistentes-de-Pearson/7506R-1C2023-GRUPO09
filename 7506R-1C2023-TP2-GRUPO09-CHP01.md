---
jupyter:
  jupytext:
    cell_metadata_filter: -all
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```python
try:
  import google.colab
  IN_COLAB = True
except:
  IN_COLAB = False
import pandas as pd 
import numpy as np

import sklearn
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split

from os.path import exists

import string

import nltk
stopwords_es = nltk.corpus.stopwords.words('spanish')

import re
from unicodedata import normalize

import tensorflow as tf

from tensorflow import keras
from keras.preprocessing.text import one_hot, Tokenizer
from keras.models import Sequential
from keras.layers.core import Activation, Dropout, Dense, SpatialDropout1D
from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM, TextVectorization
from keras_preprocessing.sequence import pad_sequences
```

```python
SEED=9
```

```python
reviewDfOriginal = pd.read_csv("./review_train.csv")
reviewDf = reviewDfOriginal.copy()
```

```python
review_pruebasOriginal = pd.read_csv("./review_test.csv")
review_pruebas = review_pruebasOriginal.copy()
```

```python
reviewDf = reviewDf.drop(["ID"],  axis='columns', inplace=False)
reviewDf
```

```python
reviewDf_x = reviewDf.drop(["sentimiento"],  axis='columns', inplace=False)

reviewDf_y = reviewDf['sentimiento'].copy()

x_train, x_test, y_train, y_test = train_test_split(reviewDf_x,
                                                    reviewDf_y,
                                                    test_size=0.30,
                                                    random_state=SEED,
                                                    shuffle=True
                                                    )
```

# Bayes Naive

```python
modeloBayesNaive = make_pipeline(TfidfVectorizer(), MultinomialNB())
```

```python
if not exists('submissions/TP2/naiveBayes-0.csv'):
    modeloBayesNaive.fit(x_train.review_es, y_train)
    prediccion = modeloBayesNaive.predict(review_pruebas.review_es)
    df_submission = pd.DataFrame({'id': review_pruebasOriginal['ID'], 'sentimiento': prediccion})
    df_submission.to_csv('submissions/naiveBayes-0.csv', index=False)
```

# Random Forest


# XGBoost



# Red Neuronal


## Pre procesamiento


Antes de tokenizar las reviews, vamos a hacer un proceso de pre procesamiento para elimiar palabras innecesarias, como preprosiciones 

```python
if not exists('reviews_filtradas.csv'):
    frasesFiltradas = []
    for index, value in reviewDf["review_es"].items():
        #Ponemos todas las palabras en lowercase
        value = value.lower()

        #Saco las stopwords
        valueFiltrado = [x for x in value.split() if x not in stopwords_es]
        #Vuelvo a unir el texto
        valueFiltrado = " ".join(valueFiltrado)

        #Saca los diacriticos de letras como vocales, etc (la ñ se mantiene)
        #Expresion regular obtenida de: https://es.stackoverflow.com/a/139811
        valueFiltrado = re.sub(r"([^n\u0300-\u036f]|n(?!\u0303(?![\u0300-\u036f])))[\u0300-\u036f]+", r"\1", 
                                normalize( "NFD", valueFiltrado), 0, re.I)
        valueFiltrado = normalize( 'NFC', valueFiltrado)

        #Saco los signos de puntuacion
        #Funcion obtenida de: https://stackoverflow.com/a/266162/13683575
        valueFiltrado =  valueFiltrado.translate(str.maketrans('', '', string.punctuation))
        valueFiltrado =  valueFiltrado.translate(str.maketrans('', '', '¡'))
        valueFiltrado =  valueFiltrado.translate(str.maketrans('', '', '¿'))
        
        #Anadimos la frase a la lista de frases filtradas
        frasesFiltradas.append(valueFiltrado)
    reviewDfFiltrado = pd.DataFrame(data={'review_es':frasesFiltradas})
    reviewDfFiltrado.to_csv('reviews_filtradas.csv', index=False)

else:
    reviewDfFiltrado = pd.read_csv("./reviews_filtradas.csv")

reviewDfFiltrado
```

```python
text_dataset = tf.data.Dataset.from_tensor_slices(reviewDfFiltrado['review_es'])
```

## Tokenizador


Creamos el tokenizador. TextVectorization() (https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization), le asigna un valor numerico a cada una de las palabras de nuestro vocabulario

```python
max_len = 50
max_features = 5000  # Maximum vocab size.

tokenizador = TextVectorization(
    output_sequence_length=max_len,
    max_tokens=max_features,
    output_mode='int',
)
```

```python
# tokenizador.adapt(reviewDfFiltrado["review_es"])
tokenizador.adapt(text_dataset.batch(64))
```

```python
tokenizador.vocabulary_size()
```

```python
# pad_sequences(tokenizador)
```

## Creamos la red neuronal

```python
embed_dim = 128
lstm_out = 196
max_fatures = 2000

model = tf.keras.models.Sequential()

model.add(tf.keras.Input(shape=(1,), dtype=tf.string))
# model.add(tf.keras.Input(shape=[], dtype=tf.string))

model.add(tokenizador)

print(model.predict(["humano disfrutar jamon"]))

model.add(Embedding(input_dim=tokenizador.vocabulary_size(), 
                    output_dim=3))

# model.add(SpatialDropout1D(0.4))

model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))

# model.add(Dense(2,activation='softmax'))
model.add(Dense(1,activation='softmax'))

# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])
model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])



print(model.summary())

```

## Entrenamiento


Transformamos la columna objetivo de "positivo" y "negativo" a 0 y 1

```python
y = reviewDf['sentimiento']
y = np.array(list(map(lambda x: 1 if x=="positivo" else 0, y)))
```

```python
x=reviewDfFiltrado["review_es"]
```

```python
x_train, x_test, y_train, y_test = train_test_split(x,
                                                    y, 
                                                    test_size=0.3,  #proporcion 70/30
                                                    random_state=SEED) #Semilla 9, como el Equipo !!
```

```python
# historia_modelo=model.fit(x_train, y_train, epochs=7, batch_size=5)
historia_modelo=model.fit(x_train, y_train, epochs=1,  validation_steps=3)
```

```python
x_test.reset_index(inplace=False).drop("index", axis=1)
```

```python
y_pred = model.predict(x_test)
```

```python
y_predCerteza = np.where(y_pred>0.7,1,0)
y_predCerteza
```

```python
ds_validacion=pd.DataFrame(y_predic_cat_ej1,y_test).reset_index()
ds_validacion.columns=['y_pred','y_real']
```
